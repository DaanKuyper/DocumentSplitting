{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaanKuyper/DocumentSplitting/blob/master/NLP_Models_Pipeline_for_retrieval_of_Implicit_Feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline for retrieval of Implicit Feedback via NLP models\n",
        "\n",
        "This python notebook depicts the necesssary code for generating NLP based insights from a large collection of text-based input. To achieve this, certain classes from the Hugging Face transformers library are utilised: https://huggingface.co/docs/transformers/index. If using Google Colab to execute this notebook, change the runtime type to GPU hardware accelerated and change the configuration (explained later) to use GPU's as well, as this drastically improves performance.\n",
        "\n",
        "For a detailed description of what this code represents and what its potential uses are, please refer to my paper on the subject, available on the GitHub repository: https://github.com/DaanKuyper/ImplicitFeedback"
      ],
      "metadata": {
        "id": "xjY8zUTWR2m5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kthVjXBEUpet",
        "outputId": "0e5c0016-ad07-4ea4-e708-6a5ab054203f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For the best performace, a GPU should be used for hardware acceleration. \n",
        "# The code below can be used to view what runtime is connected.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaKnYHC8YmL-"
      },
      "source": [
        "# Imports\n",
        "\n",
        "All the necessary python libraries are imported below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "u2k6bHXDX4TQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "x0XFwgTjYdQT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import Dataset\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CUXaWyfYsOJ"
      },
      "source": [
        "# Model definition\n",
        "\n",
        "Below the two classes for insight generation are displayed. These include a ModeConfig, used to define what results are desired from the input and which trained models are required to generate them. Additionally, the Insight_Generator class is shown, which creates and calls the classifiers used for insight generated based on passed variables."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the generating of insights we make use of the HuggingFace pipepline class: https://huggingface.co/docs/transformers/main_classes/pipelines. This pipeline class allows for the classifying of an input for specific tasks - they are therefore also named **classifiers** after construction. Because classifiers can be used for a number of different operations, there are different kinds of classifiers like text classification, summarization or translation. Therefore, for the configurations, it is important to define what kind of classifier we would like to utilize.\n",
        "\n",
        "Classifiers can be instantiated in two different ways. We can either make a classifier by passing the name of the desired pre-trained model for the specific task, which limits us to models uploaded to the extensive HuggingFace forum: https://huggingface.co/models. Or we can pass our own instances of a model and tokenizer class, again for a specific task, which allows us to fine-tune models according to our own input and validation datasets. This also allows us to save and load configurations locally. This process is explained in detail in the excellent Hugging Face documentation: https://huggingface.co/course/chapter3/1?fw=pt."
      ],
      "metadata": {
        "id": "FLge0pLomFOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierConfig():\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      task (`str`): name of specific classifier task.\n",
        "      name (`str`): name of pre-trained model.\n",
        "      tokenizer (`AutoTokenizer`, *optional*): HuggingFace tokenizer class.\n",
        "      model (`AutoModelClass`, *optional*): HuggingFace model class.\n",
        "      language (`List[str]`, *optional*): specific languages for the model.\n",
        "      args (`List[str]`, *optional*): additional arguments for the classifier.\n",
        "      useGPU (`bool`, *optional*): determines if the classifier uses GPU.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, \n",
        "               task, \n",
        "               name, \n",
        "               model=None, \n",
        "               tokenizer=None, \n",
        "               languages=[],\n",
        "               args=[],\n",
        "               useGPU=False):\n",
        "    self.task = task\n",
        "    self.name = name\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.languages = languages\n",
        "    self.args = args\n",
        "    self.device = 0 if useGPU else -1\n",
        "    self.useName = model is None or tokenizer is None \n",
        "\n",
        "\n",
        "  def toString(self):\n",
        "    # The combination of task, name and language form a unique identifier\n",
        "    # for different configurations, which allows us to access them later.\n",
        "    return f\"{self.task} on '{self.name}' for '{self.languages}' languages\"\n"
      ],
      "metadata": {
        "id": "k_h0YgRq3x5N"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Insight_Generator():\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      input (`List[str]`): List of input texts.\n",
        "      languageModel (`str`, *optional*): Model used for language detection.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      input,\n",
        "      languageModel='papluca/xlm-roberta-base-language-detection'\n",
        "  ):\n",
        "    self.input = self.preprocess(input)\n",
        "    self.languageModel = languageModel\n",
        "\n",
        "    # Subsets of input per specific language.\n",
        "    self.language_subsets = {}\n",
        "\n",
        "    # Dictionary of model insight results.\n",
        "    self.insights = {}\n",
        "\n",
        "    # Truncation on: for comments longer than 512 token sequence...\n",
        "    self.tokenizer_kwargs = {'truncation':True}\n",
        "\n",
        "  \n",
        "  def preprocess(self, input):\n",
        "    #  - Removing NaN values.\n",
        "    df = pd.DataFrame(input)\n",
        "    df.fillna('', inplace=True)\n",
        "\n",
        "    # - Removal of all potential HTML elements and \\n.\n",
        "    safe_input = [''.join(BeautifulSoup(comment).findAll(text=True))\\\n",
        "                  .replace('\\n', ' ') for comment in df.comment]\n",
        "\n",
        "    return safe_input\n",
        "\n",
        "\n",
        "  def detectLanguages(self):\n",
        "    ld_df = self.generateInsight(ClassifierConfig(\"text-classification\", \n",
        "                                                  self.languageModel))\n",
        "\n",
        "    print(f\"Detected languages: {np.unique(ld_df.label)}\")\n",
        "\n",
        "    # Link original comment back to language detection results.\n",
        "    ld_df['comment'] = self.input\n",
        "\n",
        "    # Split dataset in sets of detected language.\n",
        "    for language in ld_df.label:\n",
        "      self.language_subsets[language] = \\\n",
        "        ld_df.comment.take(np.where(ld_df.label == language)[0]).tolist()\n",
        "\n",
        "    # Set result as class property to allow for later inspection.\n",
        "    self.ld_df = ld_df\n",
        "\n",
        "\n",
        "  def generateInsight(self, config):\n",
        "    # Device=0 to utilize GPU.\n",
        "    classifier = pipeline(config.task, model=config.name, device=config.device) if config.useName \\\n",
        "      else pipeline(config.task, model=config.model, tokenizer=config.tokenizer, device=config.device)\n",
        "\n",
        "    input = self.input if config.languages == [] else \\\n",
        "      self.commentsByLanguages(config.languages).comment.tolist()\n",
        "\n",
        "    return pd.DataFrame(classifier(input, *config.args, **self.tokenizer_kwargs))\n",
        "\n",
        "\n",
        "  def generateInsights(self, configs):\n",
        "    for config in configs:\n",
        "      self.insights[config.toString()] = self.generateInsight(config)\n",
        "\n",
        "\n",
        "  def commentsByLanguages(self, languages):\n",
        "    return self.ld_df.loc[self.ld_df.label.isin(languages)]\n"
      ],
      "metadata": {
        "id": "NaY-z0McWYNx"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input\n",
        "\n",
        "As input for the NLP pipeline a list of texts is needed. The specific format for this input is as pandas.Series, where the name for the Series is 'comment'. For this, like the example shown below, we can link our google drive and access any .csv files from there. In the example below, the .csv file containing TicketVise comments is accessed, which is available on the GitHub repository. However, we can also simply define a static list. The file that is accessed using this method can be found in the github repository as well. Below the two different options are displayed in separate code blocks."
      ],
      "metadata": {
        "id": "9NM8S2jvHA0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "bzk7cqxjYgpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7aea3f-509f-476a-9760-b7405498f6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive for easy access to an input csv file.\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "train_path = '/content/drive/MyDrive/TicketVise_comments.csv'\n",
        "delimiter = ';'\n",
        "\n",
        "comments = pd.read_csv(train_path, delimiter=delimiter).comment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write input as static list of comments.\n",
        "example_comments = [\n",
        " 'These are some example comments', \n",
        " 'They can be written in differing lengths', \n",
        " 'And in multiple languages - for testing purposes', \n",
        " 'Dit is bijvoorbeeld commentaar in het nederlands!'\n",
        "]\n",
        "\n",
        "comments = pd.Series(example_comments, name='comment')"
      ],
      "metadata": {
        "id": "tjYlkmpWHqOy"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interaction\n",
        "\n",
        "Below is shown how the defined model configuration class and the insight generator class can be initiated and interacted with to generate results."
      ],
      "metadata": {
        "id": "98D4__YINcvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the constructor of the generator class the input is preprocessed \n",
        "# and stored as a class property. \n",
        "generator = Insight_Generator(comments)"
      ],
      "metadata": {
        "id": "bHMuWiwJi2W5"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language detection"
      ],
      "metadata": {
        "id": "FguVG6qyvXf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the use of language specific models later - we first use a \n",
        "# language detection model to split the input occording to languages.\n",
        "%%time\n",
        "generator.detectLanguages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL_Z4F-XjFIk",
        "outputId": "3cbcc776-8291-4238-8b40-31c4f7e9b369"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected languages: ['en' 'hi' 'nl' 'pt' 'sw' 'th' 'tr' 'ur']\n",
            "CPU times: user 9min 3s, sys: 5.22 s, total: 9min 8s\n",
            "Wall time: 9min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following can be used to view accuracy score for specific languages.\n",
        "generator.commentsByLanguages(['nl'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5YeaC08UqeWT",
        "outputId": "2440f3fd-fcff-43a3-839f-a179a9450119"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label     score                                            comment\n",
              "1       nl  0.994471  Beste Leen / TA's,    Bij mij is vraag 1 van t...\n",
              "3       nl  0.994270  Beste docent en assistenten,    Ik ben vandaag...\n",
              "4       nl  0.995082  Besta TA's,    Ik loop bij Opgave 4 vast op he...\n",
              "6       nl  0.995098  Beste studenten asistente,    Ik ben deze week...\n",
              "8       nl  0.995516  Hoi,    Ik snap het nut van de GlobDecl child ...\n",
              "...    ...       ...                                                ...\n",
              "1382    nl  0.994399  Hai,    Ik zit vast bij de Go puzzelopdracht, ...\n",
              "1384    nl  0.994828  Ik merk dat ik van best een aantal punten die ...\n",
              "1385    nl  0.995542  Is een cyclische stroom aanwezig zodra het For...\n",
              "1386    nl  0.995837  Geachte ta's en docenten van programmeertalen,...\n",
              "1387    nl  0.995021  Beste TA/docent,    Bij mij is vraag 2 van lab...\n",
              "\n",
              "[897 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea136100-ad27-4e9b-8d34-8f21533e0572\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.994471</td>\n",
              "      <td>Beste Leen / TA's,    Bij mij is vraag 1 van t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.994270</td>\n",
              "      <td>Beste docent en assistenten,    Ik ben vandaag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995082</td>\n",
              "      <td>Besta TA's,    Ik loop bij Opgave 4 vast op he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995098</td>\n",
              "      <td>Beste studenten asistente,    Ik ben deze week...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995516</td>\n",
              "      <td>Hoi,    Ik snap het nut van de GlobDecl child ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1382</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.994399</td>\n",
              "      <td>Hai,    Ik zit vast bij de Go puzzelopdracht, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1384</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.994828</td>\n",
              "      <td>Ik merk dat ik van best een aantal punten die ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995542</td>\n",
              "      <td>Is een cyclische stroom aanwezig zodra het For...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995837</td>\n",
              "      <td>Geachte ta's en docenten van programmeertalen,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>nl</td>\n",
              "      <td>0.995021</td>\n",
              "      <td>Beste TA/docent,    Bij mij is vraag 2 van lab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea136100-ad27-4e9b-8d34-8f21533e0572')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea136100-ad27-4e9b-8d34-8f21533e0572 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea136100-ad27-4e9b-8d34-8f21533e0572');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insight generation"
      ],
      "metadata": {
        "id": "50JjmqF2vZ6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired classifiers are defined as ClassifierConfig.\n",
        "# A list of these can then be passed to the insight generator.\n",
        "configs = [\n",
        "    ClassifierConfig(\"sentiment-analysis\", \n",
        "                     \"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "]\n",
        "# Don't forget to pass 'useGPU=True' when utilizing GPU!!!"
      ],
      "metadata": {
        "id": "OZsksW_mlGly"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the zero-shot-classification, which allows for input classifying \n",
        "# according to labels after the model training has taken place. \n",
        "# These labels are additional arguments for the classifier and are \n",
        "# passed to the 'args' property of the configuration.\n",
        "configs.append(\n",
        "    ClassifierConfig(\"zero-shot-classification\", \n",
        "                     \"joeddav/xlm-roberta-large-xnli\",\n",
        "                     languages=[\"en\"],\n",
        "                     args=[\"urgent\"])\n",
        ")"
      ],
      "metadata": {
        "id": "sq_jBBHas5BK"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using locally stored trained models, which allows for the use of\n",
        "# fine-tuned models and tokenizers.\n",
        "# However, for the example, a non-local model is still used.\n",
        "model_directory = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "configs.append(\n",
        "  ClassifierConfig(\"sentiment-analysis\", \n",
        "                   \"fine-tuned-model\",\n",
        "                   model=AutoModelForSequenceClassification.from_pretrained(model_directory), \n",
        "                   tokenizer=AutoTokenizer.from_pretrained(model_directory),\n",
        "                   languages=[\"en\"])\n",
        ")"
      ],
      "metadata": {
        "id": "6Mdt3GxN0YRU"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "generator.generateInsights(configs)"
      ],
      "metadata": {
        "id": "hof7YDcfxOl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results are stored within the generator.\n",
        "generator.insights"
      ],
      "metadata": {
        "id": "tmedqiZc5gBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5rOSYaTTvj"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "The data that is gathered using the insight generator model is stored within its class properties. These can thus be extruded later to show the results in more insightful ways. We can access specific results by their unique identifier, a string containing all their relative information. Below three separate ways of visualizing the results is shown. Zero-shot-classification results in a list of scores and labels, for which the visualization functions are currently not optimized. But variants of the functions could easily be implemented, or existing once made more robust. Feel free to play around with what model result is passed to the functions, and which insights can be extruded from them. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specific insights are retrieved by their unique identifiers:\n",
        "for key in generator.insights.keys():\n",
        "  print(key)"
      ],
      "metadata": {
        "id": "l_ADnv5Ju5K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extreme edge values\n",
        "\n",
        "Retrieving the extreme edge values for a specific label, sorted by the accuracy score given by the hugging face model."
      ],
      "metadata": {
        "id": "das3AtcvY8YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EdgeValues(dataframe, label, amount=5):\n",
        "  return dataframe.loc[dataframe.label == label].sort_values(by=['score'])[:amount]"
      ],
      "metadata": {
        "id": "ppaTnbtIX9Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EdgeValues(generator.insights[\"sentiment-analysis on 'nlptown/bert-base-multilingual-uncased-sentiment' for '[]' languages\"], '5 stars')"
      ],
      "metadata": {
        "id": "Zj9dOPVWYbY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EdgeValues(generator.insights[\"sentiment-analysis on 'fine-tuned-model' for '['en']' languages\"], 'POSITIVE')"
      ],
      "metadata": {
        "id": "FSLSrkuCs-qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Pie plot\n",
        "\n",
        "Pie plot depicting each specific label result in the model and its occurence."
      ],
      "metadata": {
        "id": "UkWvQ-7kZE27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LabelPiePlot(dataframe):\n",
        "  labels = np.unique(dataframe.label)\n",
        "  ld_gg = dataframe.groupby(by=dataframe.label)\n",
        "\n",
        "  means = []\n",
        "  for label in labels:\n",
        "      means.append(len(ld_gg.groups[label]) / len(dataframe))\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.pie(means, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "990NOoTal0ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LabelPiePlot(generator.insights[\"sentiment-analysis on 'nlptown/bert-base-multilingual-uncased-sentiment' for '[]' languages\"])"
      ],
      "metadata": {
        "id": "vw1Hr19V6S5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LabelPiePlot(generator.insights[\"sentiment-analysis on 'fine-tuned-model' for '['en']' languages\"])"
      ],
      "metadata": {
        "id": "sgoOTUwTsQGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scores Histogram\n",
        "Bar plot depicting the ranges in accuracy scores across the input."
      ],
      "metadata": {
        "id": "gBmg5xkmZQDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ScoreHistogram(dataframe):\n",
        "  plt.hist([round(score, 1) for score in dataframe.score], \n",
        "           lw=1, ec=\"yellow\", fc=\"green\", alpha=0.5, align='right')\n",
        "  \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "j64ArpfFH9Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ScoreHistogram(generator.insights[\"sentiment-analysis on 'nlptown/bert-base-multilingual-uncased-sentiment' for '[]' languages\"])"
      ],
      "metadata": {
        "id": "wlXUC8U9Impo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ScoreHistogram(generator.insights[\"sentiment-analysis on 'fine-tuned-model' for '['en']' languages\"])"
      ],
      "metadata": {
        "id": "Vir3TxnnsZOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3CUXaWyfYsOJ"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyP5v93ZSD/u1gfekdO7RdxX",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}